services:
  postgresql:
    image: postgres:16
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: scrapper
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - postgresql:/var/lib/postgresql/data
    networks:
      - backend

  liquibase-migrations:
    image: liquibase/liquibase:4.25
    depends_on:
      - postgresql
    command:
      - --changelog-file=master.xml
      - --driver=org.postgresql.Driver
      - --url=jdbc:postgresql://postgresql:5432/scrapper
      - --username=postgres
      - --password=postgres
      - update
    volumes:
      - ./migrations:/liquibase/changelog
    networks:
      - backend

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      - kafka

  kafka1:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zookeeper
    volumes:
      - kafka1_data:/var/lib/kafka/data
    networks:
      - kafka

  kafka2:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka2
    container_name: kafka2
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zookeeper
    volumes:
      - kafka2_data:/var/lib/kafka/data
    networks:
      - kafka

  init-kafka:
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      - kafka1
      - kafka2
    entrypoint: ['/bin/sh','-c']
    networks:
      - kafka
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka1:29092,kafka2:29093 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka1:29092,kafka2:29093 --create --if-not-exists --topic scrapper.updates --replication-factor 2 --partitions 2

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka1:29092,kafka2:29093 --list
      "

  prometheus:
    image: prom/prometheus:v2.51.2
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    networks:
      - metrics

  grafana:
    image: grafana/grafana-oss:10.4.2
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - metrics

  scrapper:
    image: tg-scrapper:latest
    ports:
      - "8080:8080"
      - "8081:8081"
    environment:
      DB_URL: jdbc:postgresql://postgresql:5432/scrapper
      DB_PASSWORD: postgres
      DB_USERNAME: postgres
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
    networks:
      - kafka
      - backend
      - metrics


  bot:
    image: tg-bot:latest
    ports:
      - "8090:8090"
      - "8091:8091"
    environment:
      TG_TOKEN: ${TG_TOKEN}
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
    networks:
      - kafka
      - metrics

volumes:
  postgresql: { }
  zookeeper_data: { }
  kafka1_data: { }
  kafka2_data: { }
  grafana_data: { }

networks:
  backend: { }
  kafka: { }
  metrics: { }
